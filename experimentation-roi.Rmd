---
title: "Experimentation Tools | Program ROI"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    css: styles.css
    vertical_layout: scroll
    logo: logo-sm.png
    favicon: favicon.png
    fig_height: 1
    navbar: 
      - { title: "Results Analysis", href: "https://sdidev.shinyapps.io/ABTestAnalysis/" }
      - { title: "Sequential App", href: "https://sdidev.shinyapps.io/sequential-test-calculator/" }
      - { title: "Sample Size", href: "https://sdidev.shinyapps.io/sample-size-calculator/" }
      - { title: "Runtime", href: "https://sdidev.shinyapps.io/sample-size-calculator-runtime/" }
      - { title: "Impact Simulation", href: "https://sdidev.shinyapps.io/test-result-simulator/" }
runtime: shiny
---


```{r setup, include=FALSE}
library(ggplot2)
library(shiny)
library(gt)
library(tidyr)
library(dplyr)
#library(scales)
library(capture)
library(tidyverse)
library(shinyjs)


# SDI colors are
# Light Orange: F58220
# Orange:FF6D00
# Dark Orange: E45C00
# Light Teal: 00A2B1
# Teal: 00747F
# Dark Teal: 004E54
# Dark Gray: 515151
# Light Gray: 9A9896

```

<script>
$('.navbar-logo').wrap('<a href="https://www.searchdiscovery.com/how-we-help/services/optimization/" target=_blank>');
</script>


Inputs {.sidebar data-width=270}
-----------------------------------------------------------------------

```{r inputs}
useShinyjs(rmd = TRUE)

inputPanel(
  h4("Simulation Values"),
  numericInput("testCt", label = "How many tests do you want to simulate?", value = 300, min = 1, max = 20000),
  numericInput("avgE", label = "Average true effect size (%)", value = 0, min = -100, max = 100),
  numericInput("traffVolume", label = "How many monthly visitors?", value = 100000, min = 1000),
  numericInput("months", label = "How many months to project value over?", value = 6, min = 1, max = 36),
  numericInput("cvValue", label = "Whats the $ value of a conversion?", value = 10, min = 0),
  numericInput("testCost", label = "Whats the average cost to produce 1 test?", value = 5000, min = 0, max = 100000),
  selectInput("dispersion", 
              label = "Effect dispersion (How wide do you want true effects to be distributed?)", 
              choices = c("Wide","Medium","Narrow"),
              selected = "Medium"),
  actionButton("simulate", label = "Simulate data")
)

inputPanel(
  h4("Experiment Configurations"),
  numericInput("alpha", label = "Confidence Level (%)", value = 95, min = 50, max = 99),
  numericInput("beta", label = "Power (%)", value = 80, min = 50, max = 99),
  numericInput("mde", label = "Minimum Detectable Effect (%)", value = 10, min = 0, max = 99),
  disabled(
    numericInput("tails", label = "WIP - How many tails?", value = 1, min = 1, max = 2)
    ),
  numericInput("base", label = "What's the base conversion rate? (%)", value = 5, min = 1, max = 99),
  disabled(
    numericInput("nonf", label = "WIP - Non-inferiority margin? (%)", value = 0, min = 0, max = 99)
  )

)


```


```{r pdfexport}
# EXPORT TO PDF
# Package from github: remotes::install_github("dreamRs/capture")
renderUI({
  div(id="exportpdf",
    capture::capture_pdf(
      selector = "body",
      filename = "TrueTestOutcomes",
      icon("download"), "Export to PDF",
      margin = 2
    )
  )
})

```

```{r storeValues, include=FALSE}
simVals <- reactiveValues(
    simulation = NULL,
    summary = NULL
  )

observeEvent(c(input$simulate, input$dispersion, input$alpha, input$beta, input$mde, input$tails, input$base, input$testCt, input$avgE, input$traffVolume, input$cvValue, input$months, input$testCost), {
  a <- 1 - (input$alpha/100)
  b <- input$beta/100 
  minEff <- input$mde/100
  tails <- if (input$tails == 2) "two" else "one"
  baseRate <- input$base/100
  nTests <- input$testCt
  avgEff <- input$avgE/100
  
  sampSize <- round(power.prop.test(
          n = NULL,
          p1 = baseRate,
          p2 = baseRate*(1+minEff),
          sig.level = a,
          power = b,
          alternative = tails
        )$n)  
  
  dispersion <- if (input$dispersion == "Wide") 750 else if (input$dispersion == "Medium") 2000 else 10000   
  
  
  trueB <- rbinom(n=nTests, size=dispersion, prob = baseRate * (1 + avgEff)) 
  #trueB <- rnorm(nTests, mean = input$avgE/100, sd = stDev/100) %>% print()
  #trueB <- (trueB+1)*baseRate %>% print()
  trueB <- trueB/dispersion
  cvCtA <- rbinom(n=nTests, size=sampSize, prob = baseRate)  
  cvCtB <- rbinom(n=nTests, size=sampSize, prob = trueB) 
  
  pvalCalc <- function (cva,cvb,samp) {
    p <- prop.test(
      x = c(cva,cvb),
      n = c(samp,samp),
      alternative = if (tails == "one") "l" else "t"
      )$p.value
    return(p)
  }
  
  testSim <- data.frame(
    aCVs = cvCtA, 
    bCVs = cvCtB, 
    aCVR = cvCtA/sampSize, 
    bCVR = cvCtB/sampSize, 
    n = sampSize)  
  
  testSim['pvalue'] <- apply(
    testSim[,c('aCVs','bCVs','n')], 
    1, 
    function(x) pvalCalc(x['aCVs'],x['bCVs'],x['n'])
    )
  
  testSim <- testSim %>%
    mutate(
      trueEff = trueB/baseRate-1, 
      obsEff = (cvCtB/sampSize)/(cvCtA/sampSize)-1, 
      effRatio = obsEff/trueEff,
      win = pvalue <= a,
      signErr = obsEff > 0 & trueEff <= 0,
      falsePos = pvalue <= a & trueEff <= 0,
      falseNeg = trueEff >= minEff & pvalue > a,
      cost = -input$testCost,
      truVal = trueEff * baseRate * input$traffVolume * input$cvValue * input$months
      ) %>%
    mutate(estVal = obsEff * baseRate * input$traffVolume * input$cvValue * input$months,
           roi = truVal + cost) %>% 
    mutate(across(where(is.numeric), ~ round(., 3)))
  
  testSum <- data.frame(
    Metric = c(
      "Count of wins",
      "Wins / Total tests",
      "False positive wins",
      "False positives / Wins",
      "False negatives (truth >= MDE)",
      "False negatives (truth > 0)",
      "True - but Observed +",
      "ROI without testing",
      "True value of wins",
      "Estimated value of wins",
      "Cost of testing",
      "ROI of testing (wins - total - cost)"
    ),
    Value = c(
      sum(testSim['win'] == TRUE),
      sum(testSim['win'] == TRUE)/nTests,
      sum(testSim['falsePos'] == TRUE),
      sum(testSim['falsePos'] == TRUE)/sum(testSim['win'] == TRUE),
      sum(testSim['falseNeg'] == TRUE),
      sum(testSim['truVal'] > 0) - sum(testSim['win'] == TRUE),
      sum(testSim['signErr'] == TRUE),
      sum(testSim['truVal']),
      sum(testSim[which(testSim[,'win']==TRUE),'truVal']),
      sum(testSim[which(testSim[,'win']==TRUE),'estVal']),
      input$testCt*input$testCost,
      sum(testSim[which(testSim[,'win']==TRUE),'truVal'])-sum(testSim['truVal'])-input$testCt*input$testCost
    )
  )
  
  simVals$simulation <- testSim
  simVals$summary <- testSum
  simVals$sample <- round(sampSize)
  
  
})

```



Row {.topRow}
-----------------------------------------------------------------------
```{r intro}
h1("Real Outcomes vs. Test Outcomes")
```

Row {data-height=380}
-----------------------------------------------------------------------
### 1. Simulate true effects {.threecol}

```{r trueEffects}
output$exp1 <- renderUI({
  div("First, we simulate the true, underlying effects, or relative difference between test and control, for our batch of tests. These are normally distributed around",
      strong(paste0(input$avgE,"%")),
  "with a ",
  strong(paste0(input$dispersion)),
  " spread."
  )
})

output$plot1 <- renderPlot({
  df <- simVals$simulation
  
  ggplot(df, aes(x=trueEff)) +
    geom_histogram(
      fill = "blue",
      alpha = .5,
      #binwidth = .001
    ) +
    geom_histogram(
      mapping = aes(x=obsEff),
      fill = "red",
      alpha = .0,
      #binwidth = .001
    ) +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    xlab("True difference in conversion rates") +
    ylab("Count of tests") +
    geom_vline(xintercept = input$avgE/100, linetype = "dashed", size = .25) +
    annotate(geom="text", x= input$avgE/100,
         y=input$testCt/20, 
         label= paste0(input$avgE,"% avg. effect"),
        # fontface = "bold",
         angle = 90,
         size = 4.0) +
    theme_light()
})

uiOutput("exp1")
plotOutput("plot1")

```


### 2. Simulate test samples {.threecol}

```{r simulatedSamples}
output$exp2 <- renderUI({
  div("Next, we create random samples for our control and test groups. The control conversion rate is ",
      strong(paste0(input$base,"%")),
      " for each test, but both control and test groups are random samples of ",
      strong(paste0(format(round(simVals$sample), big.mark=",", scientific = FALSE)," visitors,")),
      " based on selected test inputs. Observed effects are then calculated."
  )
})

output$plot2 <- renderPlot({
  df <- simVals$simulation
  
  ggplot(df, aes(x=trueEff)) +
    geom_histogram(
      fill = "blue",
      alpha = .5,
      #binwidth = .001
    ) +
    geom_histogram(
      mapping = aes(x=obsEff),
      fill = "red",
      alpha = .5,
      #binwidth = .001
    ) + 
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    xlab("True difference vs. Observed difference") +
    ylab("Count of tests") +
    geom_vline(xintercept = input$avgE/100, linetype = "dashed", size = .25) +
    annotate(geom="text", x= input$avgE/100,
         y=input$testCt/20, 
         label= paste0(input$avgE,"% avg. effect"),
        # fontface = "bold",
         angle = 90,
         size = 4.0) +
    theme_light()
})

uiOutput("exp2")
plotOutput("plot2")

```


### 3. Compare test outcomes to truth {.threecol}
```{r resultsExplained}
output$exp3 <- renderUI({
  div(
      p("Now that we have data from many tests and we know the underlying truths behind those tests, we can see the impact of random variation and controlled experimentation on aggregate business results:"),
      div(class = "highlights",
      p("Our test win rate was",
      strong(paste0(round(simVals$summary[2,2]*100),"%")),
      ", with ",
        strong(paste0(round(simVals$summary[4,2]*100),"%")),
        " of these being false positives."),
      p(strong(simVals$summary[5,2]),
        " of our false negatives had effects >= our ",
        paste0(input$mde,"% "),
        "MDE. With a cost of ",
        paste0("$",format(input$testCost, big.mark=",", scientific = FALSE)),
        " per test, we netted out with a ",
        strong(paste0("$",format(round(simVals$summary[12,2]), big.mark=",", scientific = FALSE))),
        "ROI where, without testing, the total value of our ideas was ",
        strong(paste0("$",format(round(simVals$summary[8,2]), big.mark=",", scientific = FALSE))),
        "."
      )
  )
  )
})

uiOutput("exp3")

```

Row {data-height=450}
----------------------------------------------------------------------

### Summary
```{r sumTable}
render_gt({
  gt(simVals$summary) %>%
    fmt_number(columns=vars(Value), rows=c(1,3,5,6,7), decimals = 0) %>%
    fmt_percent(columns=vars(Value), rows=c(2,4), decimals = 0) %>%
    fmt_currency(vars(Value), rows=c(8,9,10,11,12), decimals = 0) %>%
    cols_align(align = "left", columns = vars(Metric)) %>%
    #cols_align(align = "center", columns = vars(Lower, Observed, Upper)) %>%
    #cols_label(Metric = "Measure") %>%
    tab_options(table.width = pct(100))
})

```


### Value of tests
```{r dollarValue}
output$exp4 <- renderUI({
  div("We've extrapolated the value of each test by multiplying the true difference in conversion rate by ",
      strong(paste0(format(input$traffVolume, big.mark=",", scientific = FALSE))),
  " visitors per month for ",
  strong(paste0(input$months)),
  " months at a value of ",
  strong(paste0("$",format(input$cvValue, big.mark=",", scientific = FALSE))),
  " per incremental conversion. Notice how the estimated value, based on observed effect, is usually greater than the true value!"
  )
})

output$valplot <- renderPlot({
  df <- simVals$summary[8:12,1:2] %>%
    mutate(pos = Value > 0)
  
  ggplot(df, aes(x = Metric, fill = pos)) +
    geom_col(
      mapping = aes(y = Value),
      alpha = .5
    ) +
    scale_x_discrete(#guide = guide_axis(n.dodge = 2),
       limits = c("ROI without testing",
      "True value of wins",
      "Estimated value of wins",
      "Cost of testing",
      "ROI of testing (wins - total - cost)"),
       labels = c("ROI without testing" = "All - Actual",
      "True value of wins" = "Wins (Actual)",
      "Estimated value of wins" = "Wins (Estimated)",
      "Cost of testing" = "Cost",
      "ROI of testing (wins - total - cost)" = "ROI")) +
    scale_y_continuous(labels = scales::dollar) +
    scale_fill_manual(values = c("FALSE" = "red", "TRUE" = "blue")) +
    geom_text(
      mapping = aes(y = Value, label = paste0("$",format(Value, big.mark=",", digits = 0, scientific = FALSE))),
      position = position_stack(vjust = .5)
    ) +
    theme_light() +
    theme(axis.title.y = element_blank(), legend.position = "none", axis.title.x = element_blank())
})

uiOutput("exp4")
plotOutput("valplot")

```


Row {data-height=450}
-----------------------------------------------------------------------
### Winners
```{r winners}
output$exp5 <- renderUI({
  div("Any test with statistical confidence >= ",
      strong(paste0(input$alpha,"%")),
      " is a \"win\". As long as the true effect is > 0, it's a true win. It's a false positive when the observed effect is significantly positive while the true effect is <= 0. Oof! Fortunately, the false positive rate of ",
      strong(paste0(100-input$alpha,"%")),
      " allowed by our statistical design assumes the null hypothesis is only ",
      strong("barely"),
      " true every time. Since that's not the case, our actual false positive rate will always be lower than that prescribed by our design.")
})

#rmarkdown::render_delayed({
output$winplot <-  renderPlot({
    df <- simVals$simulation

    ggplot(subset(df,win==TRUE), aes(x=trueEff, fill=falsePos)) +
      geom_histogram(
        alpha = .5
        #binwidth = function(x)  (max(x)-min(x))/nclass.Sturges(x)
      ) +
      scale_fill_manual(values = c("blue", "red")) +
      scale_x_continuous(labels = scales::percent) +
      guides(color = "Error") +
      xlab("True difference in conversion rates") +
      ylab("Count of tests") +
      geom_vline(xintercept = 0-input$nonf/100, linetype = "dashed", size = .25) +
      annotate(geom="text", x= 0-input$nonf/100,
           y=simVals$summary[1,2]/15, 
           label= paste0("Null hypothesis threshold"),
          # fontface = "bold",
           angle = 90,
           size = 4.0) +
      geom_vline(xintercept = input$mde/100, linetype = "dashed", size = .25) +
      annotate(geom="text", x= input$mde/100,
           y=simVals$summary[1,2]/15, 
           label= paste0("MDE"),
          # fontface = "bold",
           angle = 90,
           size = 4.0) +
      theme_light() +
      theme(legend.position = "none")
  })
#})

uiOutput("exp5")
plotOutput("winplot")
```


### Inconclusive tests
```{r losers}
output$exp6 <- renderUI({
  div("Any insignificant test result is considered \"inconclusive\". In most cases, we'd be happy with any result > 0, but we've chosen an MDE of ",
      strong(paste0(input$mde,"%")),
      " and a power of ",
      strong(paste0(input$beta,"%")),
      " which means that if the true effect were ",
      strong(paste0(input$mde,"%")),
      " every time, we'd end up with a win, ",
      strong(paste0(input$beta,"%")),
      " of the time. But again, this assumes that the true effect is equal to our MDE in every winning scenario. That's clearly never the case, so our false negative rate will always be lower than the ",
      strong(paste0(100-input$beta,"%")),
      " prescribed by the test design.")
})

# rmarkdown::render_delayed({
output$lossplot <-  renderPlot({
    df <- simVals$simulation

    ggplot(subset(df,win==FALSE), aes(x=trueEff, fill=falseNeg)) + 
      geom_histogram(
        alpha = .5
        #binwidth = function(x) (max(x)-min(x))/nclass.Sturges(x)
      ) +
      scale_fill_manual(values = c("blue", "red")) +
      scale_x_continuous(labels = scales::percent) +
      guides(color = "Error") +
      xlab("True difference in conversion rates") +
      ylab("Count of tests") +
      geom_vline(xintercept = 0-input$nonf/100, linetype = "dashed", size = .25) +
      annotate(geom="text", x= 0-input$nonf/100,
           y=(input$testCt-simVals$summary[1,2])/15, 
           label= paste0("Null hypothesis threshold"),
          # fontface = "bold",
           angle = 90,
           size = 4.0) +
      geom_vline(xintercept = input$mde/100, linetype = "dashed", size = .25) +
      annotate(geom="text", x= input$mde/100,
           y=(input$testCt-simVals$summary[1,2])/15, 
           label= paste0("MDE"),
          # fontface = "bold",
           angle = 90,
           size = 4.0) +
      theme_light() +
      theme(legend.position = "none")
  })
# })

uiOutput("exp6")
plotOutput("lossplot")
```

Row {data-height=300}
-----------------------------------------------------------------------
### Sample Data: Each row is a simulated test outcome based on your inputs

```{r}
rmarkdown::render_delayed({
  render_gt({
    
    gt(head(simVals$simulation[,c(3:8,10,12,13,15,16)],10)) %>%
      fmt_percent(columns=vars(aCVR, bCVR, trueEff, obsEff), decimals = 1) %>%
      fmt_number(columns=vars(pvalue), decimals = 3) %>%
      fmt_currency(columns=vars(truVal, estVal), decimals = 0) %>%
      fmt_number(columns=vars(n), decimals = 0) %>%
      #cols_align(align = "left", columns = vars(Metric)) %>%
      #cols_align(align = "center", columns = vars(Lower, Observed, Upper)) %>%
      #cols_label(Metric = "Measure") %>%
      tab_options(table.width = pct(100))
  })
})

```


Row {data-height=50}
-----------------------------------------------------------------------
version 1.3  
To see version history, report bugs and submit feature requests [click here](https://github.com/alphanumerritt/TrueTestOutcomes/issues){target="_blank"}.


